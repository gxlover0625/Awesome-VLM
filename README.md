<div align="center">

# Awesome Vision-Language Model

[![License: MIT](https://img.shields.io/badge/License-MIT-purple.svg)](LICENSE)
[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

</div>

## üî• News
- **2025.06**: This repository shares the latest papers, tools, and open-source projects in the VLM / MLLM field and **will be regularly updated**.

## üåü Introduction
I am a researcher specializing in VLM / MLLM technology at Zhejiang University. This curated repository has been established with the aim of sharing cutting-edge papers, innovative technologies, and notable open-source projects within this domain.

## üìù  Paper
### Multi-Image Benchmark



## üåã Foundation Model

## üê≥ Training
- [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory) Unified Efficient Fine-Tuning of 100+ LLMs & VLMs (ACL 2024) ![Star](https://img.shields.io/github/stars/hiyouga/LLaMA-Factory.svg?style=social&label=Star)
- [EasyR1](https://github.com/hiyouga/EasyR1) An Efficient, Scalable, Multi-Modality RL Training Framework based on veRL. ![Star](https://img.shields.io/github/stars/hiyouga/EasyR1.svg?style=social&label=Star)


## ‚ù§Ô∏è Other Awesome Projects
- [Awesome-Multimodal-Large-Language-Models](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models) Latest Advances on Multimodal Large Language Models. ![Star](https://img.shields.io/github/stars/BradyFU/Awesome-Multimodal-Large-Language-Models.svg?style=social&label=Star)
- [Awesome-RL-based-Reasoning-MLLMs](https://github.com/Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs) This repository provides valuable reference for researchers in the field of multimodality, please start your exploratory travel in RL-based Reasoning MLLMs! ![Star](https://img.shields.io/github/stars/Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs.svg?style=social&label=Star)