<div align="center">

# Awesome Vision-Language Model

[![License: MIT](https://img.shields.io/badge/License-MIT-purple.svg)](LICENSE)
[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

</div>

## üî• News
- **2025.06**: This repository shares the latest papers, tools, and open-source projects in the VLM / MLLM field and **will be regularly updated**.

## üåü Introduction
I am a researcher specializing in VLM / MLLM technology at Zhejiang University. This curated repository has been established with the aim of sharing cutting-edge papers, innovative technologies, and notable open-source projects within this domain.

## üìù  Paper
### Multi-Image Benchmark



## üåã Foundation Model

## üî® Deploying
- [ollama](https://github.com/ollama/ollama) Get up and running with Llama 3.3, DeepSeek-R1, Phi-4, Gemma 3, Mistral Small 3.1 and other large language models. ![Star](https://img.shields.io/github/stars/ollama/ollama.svg?style=social&label=Star)
- [vllm](https://github.com/vllm-project/vllm) A high-throughput and memory-efficient inference and serving engine for LLMs ![Star](https://img.shields.io/github/stars/vllm-project/vllm.svg?style=social&label=Star)
- [lmdeploy](https://github.com/InternLM/lmdeploy) LMDeploy is a toolkit for compressing, deploying, and serving LLMs. ![Star](https://img.shields.io/github/stars/InternLM/lmdeploy.svg?style=social&label=Star)

## üê≥ Training
- [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory) Unified Efficient Fine-Tuning of 100+ LLMs & VLMs (ACL 2024) ![Star](https://img.shields.io/github/stars/hiyouga/LLaMA-Factory.svg?style=social&label=Star)
- [ms-swift](https://github.com/modelscope/ms-swift) Use PEFT or Full-parameter to CPT/SFT/DPO/GRPO 500+ LLMs (Qwen3, Qwen3-MoE, Llama4, InternLM3, DeepSeek-R1, ...) and 200+ MLLMs (Qwen2.5-VL, Qwen2.5-Omni, Qwen2-Audio, Ovis2, InternVL3, Llava, GLM4v, Phi4, ...) (AAAI 2025). ![Star](https://img.shields.io/github/stars/modelscope/ms-swift.svg?style=social&label=Star)
- [EasyR1](https://github.com/hiyouga/EasyR1) An Efficient, Scalable, Multi-Modality RL Training Framework based on veRL. ![Star](https://img.shields.io/github/stars/hiyouga/EasyR1.svg?style=social&label=Star)


## ‚ù§Ô∏è Other Awesome Projects
- [Awesome-Multimodal-Large-Language-Models](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models) Latest Advances on Multimodal Large Language Models. ![Star](https://img.shields.io/github/stars/BradyFU/Awesome-Multimodal-Large-Language-Models.svg?style=social&label=Star)
- [Awesome-RL-based-Reasoning-MLLMs](https://github.com/Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs) This repository provides valuable reference for researchers in the field of multimodality, please start your exploratory travel in RL-based Reasoning MLLMs! ![Star](https://img.shields.io/github/stars/Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs.svg?style=social&label=Star)